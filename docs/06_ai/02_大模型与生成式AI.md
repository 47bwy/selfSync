# 

å¤§æ¨¡åž‹åº”ç”¨å¼€å‘å·¥ç¨‹å¸ˆ

1. å·¥ä½œå†…å®¹ï¼š

* è´Ÿè´£å¤§è¯­è¨€æ¨¡åž‹çš„åº”ç”¨ç ”ç©¶å’Œæ¨¡åž‹æ€§èƒ½è¯„ä¼°
* è´Ÿè´£å¤§æ¨¡åž‹æœ¬åœ°ç§æœ‰åŒ–éƒ¨ç½²å’Œå¾®è°ƒ
* è´Ÿè´£ AI æ™ºèƒ½ä½“å¼€å‘å’Œå¤šæ™ºèƒ½ä½“åä½œäº§å“ç ”å‘
* åˆ©ç”¨ SFTã€RLHFã€æç¤ºè¯å·¥ç¨‹ç­‰æŠ€æœ¯æé«˜äº§å“æ€§èƒ½
* ååŠ©äº§å“ç»ç†ç¡®ä¿ AI æ™ºèƒ½ä½“åº”ç”¨ç¬¦åˆéœ€æ±‚

2. æŠ€èƒ½éœ€æ±‚ï¼š

* Python è¯­è¨€åŠå…¶å¸¸ç”¨ä¸‰æ–¹åº“
* é¢„è®­ç»ƒæ¨¡åž‹ï¼ˆtransformersï¼‰å’Œæç¤ºè¯å·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰
* æ™ºèƒ½ä½“å¼€å‘æ¡†æž¶ï¼ˆLangChainã€LlamaIndexã€autogenç­‰ï¼‰
* å‘é‡æ•°æ®åº“ï¼ˆFAISSã€Chromaç­‰ï¼‰å’Œ RAGï¼ˆæ£€ç´¢å¢žå¼ºç”Ÿæˆï¼‰
* å…¶ä»–ç›¸å…³å·¥å…·ï¼ˆDifyã€Haystackã€MetaGPTç­‰ï¼‰





### ðŸž Transformer

#### ðŸŽ¯ ç®€ä»‹

Transformer æ¨¡åž‹æœ¬è´¨ä¸Šéƒ½æ˜¯é¢„è®­ç»ƒè¯­è¨€æ¨¡åž‹ï¼Œå¤§éƒ½é‡‡ç”¨è‡ªç›‘ç£å­¦ä¹  (Self-supervised learning) çš„æ–¹å¼åœ¨å¤§é‡ç”Ÿè¯­æ–™ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè®­ç»ƒè¿™äº› Transformer æ¨¡åž‹å®Œå…¨ä¸éœ€è¦äººå·¥æ ‡æ³¨æ•°æ®ã€‚



**ä¸¤ä¸ªè‘—å Transformer æ¨¡åž‹**

* GPT (the Generative Pretrained Transformer)ï¼›
* BERT (Bidirectional Encoder Representations from Transformers)ã€‚



**transformersåº“çš„ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š**

- æä¾›ä¸°å¯Œçš„é¢„è®­ç»ƒæ¨¡åž‹ï¼Œæ¶µç›–äº†ç›®å‰ä¸»æµçš„NLPä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬åˆ†ç±»ã€ç”Ÿæˆã€æ‘˜è¦ã€é—®ç­”ç­‰ã€‚
- æä¾›ç®€æ´çš„APIæŽ¥å£ï¼Œä½¿å¾—ç”¨æˆ·å¯ä»¥å¿«é€Ÿä¸Šæ‰‹ï¼Œæ— éœ€å…³æ³¨æ¨¡åž‹çš„åº•å±‚å®žçŽ°ç»†èŠ‚ã€‚
- æ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¡†æž¶ï¼Œå¦‚PyTorchå’ŒTensorFlowï¼Œæ–¹ä¾¿ç”¨æˆ·æ ¹æ®è‡ªå·±çš„éœ€æ±‚è¿›è¡Œé€‰æ‹©ã€‚
- æä¾›é«˜æ•ˆçš„æ€§èƒ½ï¼Œæ”¯æŒå¤šGPUå’Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œæ»¡è¶³å¤§è§„æ¨¡æ•°æ®å¤„ç†çš„éœ€æ±‚ã€‚

**transformersåº“çš„ä¸»è¦ä¼˜åŠ¿åŒ…æ‹¬ï¼š**

- å¼€æºä¸”æŒç»­æ›´æ–°ï¼Œç”¨æˆ·å¯ä»¥éšæ—¶èŽ·å–åˆ°æœ€æ–°çš„æ¨¡åž‹å’ŒåŠŸèƒ½ã€‚
- ç¤¾åŒºæ´»è·ƒï¼Œæœ‰å¤§é‡çš„æ•™ç¨‹å’Œæ¡ˆä¾‹ä¾›ç”¨æˆ·å‚è€ƒï¼Œæ–¹ä¾¿ç”¨æˆ·å­¦ä¹ å’Œäº¤æµã€‚
- æ¨¡å—åŒ–è®¾è®¡ï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®éœ€æ±‚çµæ´»ç»„åˆæ¨¡åž‹çš„å„ä¸ªéƒ¨åˆ†ï¼Œå®žçŽ°å®šåˆ¶åŒ–çš„åº”ç”¨ã€‚



**Transformer çš„ç»“æž„**

æ ‡å‡†çš„ Transformer æ¨¡åž‹ä¸»è¦ç”±ä¸¤ä¸ªæ¨¡å—æž„æˆï¼š

* Encoderï¼ˆå·¦è¾¹ï¼‰ï¼šè´Ÿè´£ç†è§£è¾“å…¥æ–‡æœ¬ï¼Œä¸ºæ¯ä¸ªè¾“å…¥æž„é€ å¯¹åº”çš„è¯­ä¹‰è¡¨ç¤ºï¼ˆè¯­ä¹‰ç‰¹å¾ï¼‰ï¼›
* Decoderï¼ˆå³è¾¹ï¼‰ï¼šè´Ÿè´£ç”Ÿæˆè¾“å‡ºï¼Œä½¿ç”¨ Encoder è¾“å‡ºçš„è¯­ä¹‰è¡¨ç¤ºç»“åˆå…¶ä»–è¾“å…¥æ¥ç”Ÿæˆç›®æ ‡åºåˆ—ã€‚
![pictures](../pictures/transformer.png)

**Transformer å®¶æ—**

è™½ç„¶æ–°çš„ Transformer æ¨¡åž‹å±‚å‡ºä¸ç©·ï¼Œä½†æ˜¯å®ƒä»¬ä¾ç„¶å¯ä»¥è¢«å½’çº³åˆ°ä»¥ä¸‹ä¸‰ç§ç»“æž„ä¸­ï¼š

![pictures](../pictures/transformer-family.png)


####  ðŸŽ¯Transformer æ³¨æ„åŠ›æœºåˆ¶

Transformer æ¨¡åž‹ä¹‹æ‰€ä»¥å¦‚æ­¤å¼ºå¤§ï¼Œæ˜¯å› ä¸ºå®ƒæŠ›å¼ƒäº†ä¹‹å‰å¹¿æ³›é‡‡ç”¨çš„å¾ªçŽ¯ç½‘ç»œå’Œå·ç§¯ç½‘ç»œï¼Œè€Œé‡‡ç”¨äº†ä¸€ç§ç‰¹æ®Šçš„ç»“æž„â€”â€”æ³¨æ„åŠ›æœºåˆ¶ (Attention) æ¥å»ºæ¨¡æ–‡æœ¬ã€‚



#### ðŸŽ¯ pipelines

Transformers åº“å°†ç›®å‰çš„ NLP ä»»åŠ¡å½’çº³ä¸ºå‡ ä¸‹å‡ ç±»ï¼š

- **æ–‡æœ¬åˆ†ç±»ï¼š**ä¾‹å¦‚æƒ…æ„Ÿåˆ†æžã€å¥å­å¯¹å…³ç³»åˆ¤æ–­ç­‰ï¼›
- **å¯¹æ–‡æœ¬ä¸­çš„è¯è¯­è¿›è¡Œåˆ†ç±»ï¼š**ä¾‹å¦‚è¯æ€§æ ‡æ³¨ (POS)ã€å‘½åå®žä½“è¯†åˆ« (NER) ç­‰ï¼›
- **æ–‡æœ¬ç”Ÿæˆï¼š**ä¾‹å¦‚å¡«å……é¢„è®¾çš„æ¨¡æ¿ (prompt)ã€é¢„æµ‹æ–‡æœ¬ä¸­è¢«é®æŽ©æŽ‰ (masked) çš„è¯è¯­ï¼›
- **ä»Žæ–‡æœ¬ä¸­æŠ½å–ç­”æ¡ˆï¼š**ä¾‹å¦‚æ ¹æ®ç»™å®šçš„é—®é¢˜ä»Žä¸€æ®µæ–‡æœ¬ä¸­æŠ½å–å‡ºå¯¹åº”çš„ç­”æ¡ˆï¼›
- **æ ¹æ®è¾“å…¥æ–‡æœ¬ç”Ÿæˆæ–°çš„å¥å­ï¼š**ä¾‹å¦‚æ–‡æœ¬ç¿»è¯‘ã€è‡ªåŠ¨æ‘˜è¦ç­‰ã€‚

Transformers åº“æœ€åŸºç¡€çš„å¯¹è±¡å°±æ˜¯ `pipeline()` å‡½æ•°ï¼Œå®ƒå°è£…äº†é¢„è®­ç»ƒæ¨¡åž‹å’Œå¯¹åº”çš„å‰å¤„ç†å’ŒåŽå¤„ç†çŽ¯èŠ‚ã€‚æˆ‘ä»¬åªéœ€è¾“å…¥æ–‡æœ¬ï¼Œå°±èƒ½å¾—åˆ°é¢„æœŸçš„ç­”æ¡ˆã€‚ç›®å‰å¸¸ç”¨çš„ [pipelines](https://huggingface.co/docs/transformers/main_classes/pipelines) æœ‰ï¼š

- `feature-extraction` ï¼ˆèŽ·å¾—æ–‡æœ¬çš„å‘é‡åŒ–è¡¨ç¤ºï¼‰
- `fill-mask` ï¼ˆå¡«å……è¢«é®ç›–çš„è¯ã€ç‰‡æ®µï¼‰
- `ner`ï¼ˆå‘½åå®žä½“è¯†åˆ«ï¼‰
- `question-answering` ï¼ˆè‡ªåŠ¨é—®ç­”ï¼‰
- `sentiment-analysis` ï¼ˆæƒ…æ„Ÿåˆ†æžï¼‰
- `summarization` ï¼ˆè‡ªåŠ¨æ‘˜è¦ï¼‰
- `text-generation` ï¼ˆæ–‡æœ¬ç”Ÿæˆï¼‰
- `translation` ï¼ˆæœºå™¨ç¿»è¯‘ï¼‰
- `zero-shot-classification` ï¼ˆé›¶è®­ç»ƒæ ·æœ¬åˆ†ç±»ï¼‰



### ðŸž Pytorch

[Pytorch](https://pytorch.org/) ç”± Facebook äººå·¥æ™ºèƒ½ç ”ç©¶é™¢äºŽ 2017 å¹´æŽ¨å‡ºï¼Œå…·æœ‰å¼ºå¤§çš„ GPU åŠ é€Ÿå¼ é‡è®¡ç®—åŠŸèƒ½ï¼Œå¹¶ä¸”èƒ½å¤Ÿè‡ªåŠ¨è¿›è¡Œå¾®åˆ†è®¡ç®—ï¼Œä»Žè€Œå¯ä»¥ä½¿ç”¨åŸºäºŽæ¢¯åº¦çš„æ–¹æ³•å¯¹æ¨¡åž‹å‚æ•°è¿›è¡Œä¼˜åŒ–ã€‚æˆªè‡³ 2022 å¹´ 8 æœˆï¼ŒPyTorch å·²ç»å’Œ Linux å†…æ ¸ã€Kubernetes ç­‰å¹¶åˆ—æˆä¸ºä¸–ç•Œä¸Šå¢žé•¿æœ€å¿«çš„ 5 ä¸ªå¼€æºç¤¾åŒºä¹‹ä¸€ã€‚çŽ°åœ¨åœ¨ NeurIPSã€ICML ç­‰ç­‰æœºå™¨å­¦ä¹ é¡¶ä¼šä¸­ï¼Œæœ‰è¶…è¿‡ 80% ç ”ç©¶äººå‘˜ç”¨çš„éƒ½æ˜¯ PyTorchã€‚

#### ðŸŽ¯ Pytorchçš„ä¼˜ç‚¹

**1. åŠ¨æ€è®¡ç®—å›¾**

PyTorchæœ€çªå‡ºçš„ä¼˜ç‚¹ä¹‹ä¸€å°±æ˜¯å®ƒä½¿ç”¨äº†åŠ¨æ€è®¡ç®—å›¾ï¼ˆDynamic Computation Graphsï¼ŒDCGsï¼‰ï¼Œä¸ŽTensorFlowå’Œå…¶ä»–æ¡†æž¶ä½¿ç”¨çš„é™æ€è®¡ç®—å›¾ä¸åŒã€‚åŠ¨æ€è®¡ç®—å›¾å…è®¸ä½ åœ¨è¿è¡Œæ—¶æ›´æ”¹å›¾çš„è¡Œä¸ºã€‚è¿™ä½¿å¾—PyTorchéžå¸¸çµæ´»ï¼Œåœ¨å¤„ç†ä¸ç¡®å®šæ€§æˆ–å¤æ‚æ€§æ—¶å…·æœ‰ä¼˜åŠ¿ï¼Œå› æ­¤éžå¸¸é€‚åˆç ”ç©¶å’ŒåŽŸåž‹è®¾è®¡ã€‚

**2. æ˜“ç”¨æ€§**

PyTorchè¢«è®¾è®¡æˆæ˜“äºŽç†è§£å’Œä½¿ç”¨ã€‚å…¶APIè®¾è®¡çš„ç›´è§‚æ€§ä½¿å¾—å­¦ä¹ å’Œä½¿ç”¨PyTorchæˆä¸ºä¸€ä»¶éžå¸¸æ„‰å¿«çš„äº‹æƒ…ã€‚æ­¤å¤–ï¼Œç”±äºŽPyTorchä¸ŽPythonçš„æ·±åº¦é›†æˆï¼Œå®ƒåœ¨Pythonç¨‹åºå‘˜ä¸­éžå¸¸æµè¡Œã€‚

**3. æ˜“äºŽè°ƒè¯•**

ç”±äºŽPyTorchçš„åŠ¨æ€æ€§å’ŒPythonæ€§è´¨ï¼Œè°ƒè¯•PyTorchç¨‹åºå˜å¾—ç›¸å½“ç›´æŽ¥ã€‚ä½ å¯ä»¥ä½¿ç”¨Pythonçš„æ ‡å‡†è°ƒè¯•å·¥å…·ï¼Œå¦‚PDBæˆ–PyCharmï¼Œç›´æŽ¥æŸ¥çœ‹æ¯ä¸ªæ“ä½œçš„ç»“æžœå’Œä¸­é—´å˜é‡çš„çŠ¶æ€ã€‚

**4. å¼ºå¤§çš„ç¤¾åŒºæ”¯æŒ**

PyTorchçš„ç¤¾åŒºéžå¸¸æ´»è·ƒå’Œæ”¯æŒã€‚å®˜æ–¹è®ºå›ã€GitHubã€Stack Overflowç­‰å¹³å°ä¸Šæœ‰å¤§é‡çš„PyTorchç”¨æˆ·å’Œå¼€å‘è€…ï¼Œä½ å¯ä»¥ä»Žä¸­æ‰¾åˆ°å¤§é‡çš„èµ„æºå’Œå¸®åŠ©ã€‚

**5. å¹¿æ³›çš„é¢„è®­ç»ƒæ¨¡åž‹**

PyTorchæä¾›äº†å¤§é‡çš„é¢„è®­ç»ƒæ¨¡åž‹ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºŽResNetï¼ŒInceptionï¼ŒSqueezeNet ç­‰ç­‰ã€‚è¿™äº›é¢„è®­ç»ƒæ¨¡åž‹å¯ä»¥å¸®åŠ©ä½ å¿«é€Ÿå¼€å§‹æ–°çš„é¡¹ç›®ã€‚

**6. é«˜æ•ˆçš„GPUåˆ©ç”¨**

PyTorchå¯ä»¥éžå¸¸é«˜æ•ˆåœ°åˆ©ç”¨ NVIDIA çš„ CUDA åº“æ¥è¿›è¡ŒGPUè®¡ç®—ã€‚åŒæ—¶ï¼Œå®ƒè¿˜æ”¯æŒåˆ†å¸ƒå¼è®¡ç®—ï¼Œè®©ä½ å¯ä»¥åœ¨å¤šä¸ªGPUæˆ–æœåŠ¡å™¨ä¸Šè®­ç»ƒæ¨¡åž‹ã€‚

#### ðŸŽ¯ Pytorchçš„ä½¿ç”¨åœºæ™¯

**1. è®¡ç®—æœºè§†è§‰**

åœ¨è®¡ç®—æœºè§†è§‰æ–¹é¢ï¼ŒPyTorchæä¾›äº†è®¸å¤šé¢„è®­ç»ƒæ¨¡åž‹ï¼ˆå¦‚ResNetï¼ŒVGGï¼ŒInceptionç­‰ï¼‰å’Œå·¥å…·ï¼ˆå¦‚TorchVisionï¼Œå¯ä»¥ç”¨äºŽå›¾åƒåˆ†ç±»ã€ç‰©ä½“æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²å’Œå›¾åƒç”Ÿæˆç­‰ä»»åŠ¡ã€‚è¿™äº›é¢„è®­ç»ƒæ¨¡åž‹å’Œå·¥å…·å¤§å¤§ç®€åŒ–äº†å¼€å‘è®¡ç®—æœºè§†è§‰åº”ç”¨çš„è¿‡ç¨‹ã€‚

**2. è‡ªç„¶è¯­è¨€å¤„ç†**

åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é¢†åŸŸï¼ŒPyTorchçš„åŠ¨æ€è®¡ç®—å›¾ç‰¹æ€§ä½¿å¾—å…¶éžå¸¸é€‚åˆå¤„ç†å˜é•¿è¾“å…¥ï¼Œè¿™å¯¹äºŽè®¸å¤šNLPä»»åŠ¡æ¥è¯´æ˜¯éžå¸¸é‡è¦çš„ã€‚åŒæ—¶ï¼ŒPyTorchä¹Ÿæä¾›äº†ä¸€ç³»åˆ—çš„NLPå·¥å…·å’Œé¢„è®­ç»ƒæ¨¡åž‹ï¼ˆå¦‚Transformerç­‰ï¼‰ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬å¤„ç†æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æžã€å‘½åå®žä½“è¯†åˆ«ã€æœºå™¨ç¿»è¯‘å’Œé—®ç­”ç³»ç»Ÿç­‰ä»»åŠ¡ã€‚

**3. ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ**

ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰æ˜¯ä¸€ç§å¼ºå¤§çš„æ·±åº¦å­¦ä¹ æ¨¡åž‹ï¼Œè¢«å¹¿æ³›åº”ç”¨äºŽå›¾åƒç”Ÿæˆã€å›¾åƒåˆ°å›¾åƒçš„è½¬æ¢ã€æ ·å¼è¿ç§»å’Œæ•°æ®å¢žå¼ºç­‰ä»»åŠ¡ã€‚PyTorchçš„çµæ´»æ€§ä½¿å¾—å…¶éžå¸¸é€‚åˆå¼€å‘å’Œè®­ç»ƒGANæ¨¡åž‹ã€‚

**4. å¼ºåŒ–å­¦ä¹ **

å¼ºåŒ–å­¦ä¹ æ˜¯ä¸€ç§å­¦ä¹ æ–¹æ³•ï¼Œå…¶ä¸­æ™ºèƒ½ä½“é€šè¿‡ä¸ŽçŽ¯å¢ƒçš„äº¤äº’æ¥å­¦ä¹ å¦‚ä½•æ‰§è¡Œä»»åŠ¡ã€‚PyTorchçš„åŠ¨æ€è®¡ç®—å›¾å’Œæ˜“äºŽä½¿ç”¨çš„APIä½¿å¾—å…¶åœ¨å®žçŽ°å¼ºåŒ–å­¦ä¹ ç®—æ³•æ—¶è¡¨çŽ°å‡ºæžé«˜çš„æ•ˆçŽ‡ã€‚

**5. æ—¶åºæ•°æ®åˆ†æž**

åœ¨å¤„ç†æ—¶åºæ•°æ®çš„ä»»åŠ¡ä¸­ï¼Œå¦‚è¯­éŸ³è¯†åˆ«ã€æ—¶é—´åºåˆ—é¢„æµ‹ç­‰ï¼ŒPyTorchçš„åŠ¨æ€è®¡ç®—å›¾ä¸ºå¤„ç†å¯å˜é•¿åº¦çš„åºåˆ—æ•°æ®æä¾›äº†ä¾¿åˆ©ã€‚åŒæ—¶ï¼ŒPyTorchæä¾›äº†åŒ…æ‹¬RNNã€LSTMã€GRUåœ¨å†…çš„å„ç§å¾ªçŽ¯ç¥žç»ç½‘ç»œæ¨¡åž‹ã€‚




#### ðŸŽ¯ å¼ é‡

å¼ é‡ (Tensor) æ˜¯æ·±åº¦å­¦ä¹ çš„åŸºç¡€ï¼Œä¾‹å¦‚å¸¸è§çš„ 0 ç»´å¼ é‡ç§°ä¸ºæ ‡é‡ (scalar)ã€1 ç»´å¼ é‡ç§°ä¸ºå‘é‡ (vector)ã€2 ç»´å¼ é‡ç§°ä¸ºçŸ©é˜µ (matrix)ã€‚Pytorch æœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªåŸºäºŽå¼ é‡çš„æ•°å­¦è®¡ç®—å·¥å…·åŒ…ï¼Œå®ƒæä¾›äº†å¤šç§æ–¹å¼æ¥åˆ›å»ºå¼ é‡ï¼š



```python
>>> import torch
>>> torch.empty(2, 3) # empty tensor (uninitialized), shape (2,3)
tensor([[2.7508e+23, 4.3546e+27, 7.5571e+31],
        [2.0283e-19, 3.0981e+32, 1.8496e+20]])
>>> torch.rand(2, 3) # random tensor, each value taken from [0,1)
tensor([[0.8892, 0.2503, 0.2827],
        [0.9474, 0.5373, 0.4672]])
>>> torch.randn(2, 3) # random tensor, each value taken from standard normal distribution
tensor([[-0.4541, -1.1986,  0.1952],
        [ 0.9518,  1.3268, -0.4778]])
>>> torch.zeros(2, 3, dtype=torch.long) # long integer zero tensor
tensor([[0, 0, 0],
        [0, 0, 0]])
>>> torch.zeros(2, 3, dtype=torch.double) # double float zero tensor
tensor([[0., 0., 0.],
        [0., 0., 0.]], dtype=torch.float64)
>>> torch.arange(10)
tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
```



